# Great Papers Towards LLM Intelligence

Researchers have made remarkable and groundbreaking achievements in exploring the mechanisms and the fundamental nature of intelligence in AI models, particularly LLMs. This paper repository aims to document these milestones, providing a quick overview of the advancements in this field.

## 2025

* Sparse Autoencoders Do Not Find Canonical Units of Analysis [link](https://arxiv.org/abs/2502.04878) 2025.2 [*Feature Extracting*]
* Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment [link](https://arxiv.org/abs/2502.03714) 2025.2 [*Feature Extracting*] [*Multimodality*]
* Low-Rank Adapting Models for Sparse Autoencoders [link](https://arxiv.org/pdf/2501.19406) 2025.1 [*Feature Extracting*] [*finetune*]
* AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders [link](https://arxiv.org/abs/2501.17148) 2025.1 [*Feature Extracting*] [*Steering*]
* Concept Steerers: Leveraging K-Sparse Autoencoders for Controllable Generations [link](https://arxiv.org/abs/2501.19066) 2025.1 [*Feature Extracting*] [*Multimodality*]
* Sparse Autoencoders Trained on the Same Data Learn Different Features [link](https://arxiv.org/pdf/2501.16615) 2025.1    [*Feature Extracting*]
* How GPT learns layer by layer [link](https://arxiv.org/abs/2501.07108) 2025.1 [*Feature Extracting*]

## 2024 & Earlier

- Tracking the Feature Dynamics in LLM Training: A Mechanistic Study [link](https://arxiv.org/abs/2412.17626) 2024.12 [*Feature Extracting*]
- Towards Unifying Interpretability and Control: Evaluation via Intervention [link](https://arxiv.org/abs/2411.04430) 2024.11 [*Feature Extracting*] [*Steering*]
- A generative framework to bridge data-driven models and scientific theories in language neuroscience [link](https://arxiv.org/abs/2410.00812) 2024.10  [*Human Comparisons (Cognition & linguistics)*]
- Evaluating feature steering: A case study in mitigating social biases [link](https://www.anthropic.com/research/evaluating-feature-steering) 2024.10 [*Feature Extracting*]
- Sparse Crosscoders for Cross-Layer Features and Model Diffing [link](https://transformer-circuits.pub/2024/crosscoders/index.html) 2024.10 [*Feature Extracting*]
- Automatically Interpreting Millions of Features in Large Language Models [link](https://arxiv.org/pdf/2410.13928) 2024.10 [*Feature Extracting*]
- Using Dictionary Learning Features as Classifiers [link](https://transformer-circuits.pub/2024/features-as-classifiers/index.html) 2024.10 [*Feature Extracting*]
- Sparse Autoencoders Reveal Universal Feature Spaces Across Large Language Models [link](https://arxiv.org/pdf/2410.06981) 2024.10 [*Feature Extracting*]
- Scaling Automatic Neuron Description [link](https://transluce.org/neuron-descriptions) 2024.10 [*Neuron & Circuits Analysis*]
- Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis [link](https://arxiv.org/pdf/2409.14144) 2024.09 [*Neuron & Circuits Analysis*]
- Interpretability Evals for Dictionary Learning [link](https://transformer-circuits.pub/2024/august-update/index.html#interp-evals) 2024.08 [*Feature Extracting*]
- Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2 [link](https://arxiv.org/pdf/2408.05147) 2024.08 [*Feature Extracting*]
- The Platonic Representation Hypothesis [link](https://arxiv.org/pdf/2405.07987) 2024.07 [*Human Comparisons (Cognition & linguistics)*]
- Scaling and evaluating sparse autoencoders [link](https://cdn.openai.com/papers/sparse-autoencoders.pdf) 2024.06 [*Feature Extracting*]
- Hypothesis Testing the Circuit Hypothesis in LLMs [link](https://openreview.net/forum?id=ibSNv9cldu) 2024.06 [*Neuron & Circuits Analysis*]
- Shared functional specialization in transformer-based language models and the human brain [link](https://www.nature.com/articles/s41467-024-49173-5) 2024.06 [*Human Comparisons (Cognition & linguistics)*]
- Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet [link](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html) 2024.05 [*Feature Extracting*]
- Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns [link](https://pubmed.ncbi.nlm.nih.gov/38553456/) 2024.05 [*Human Comparisons (Cognition & linguistics)*]
- Reflections on Qualitative Research [link](https://transformer-circuits.pub/2024/qualitative-essay/index.html) 2024.03 [*Feature Extracting*]
- RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations [link](https://arxiv.org/pdf/2402.17700) 2024.02 [*Neuron & Circuits Analysis*]
- Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models [link](https://arxiv.org/pdf/2402.16438) 2024.02 [*Neuron & Circuits Analysis*]
- Successor Heads: Recurring, Interpretable Attention Heads In The Wild [link](https://arxiv.org/abs/2312.09230) 2023.12 [*Neuron & Circuits Analysis*]
- Towards Monosemanticity: Decomposing Language Models With Dictionary Learning [link](https://transformer-circuits.pub/2023/monosemantic-features/index.html) 2023.10 [*Feature Extracting*]
- Sparse Autoencoders Find Highly Interpretable Features in Language Models [link](https://arxiv.org/pdf/2309.08600) 2023.09 [*Feature Extracting*]
- Toy Models of Superposition [link](https://transformer-circuits.pub/2022/toy_model/index.html) 2022.09 [*Feature Extracting*]
- Semantic Structure in Deep Learning [link](https://www.annualreviews.org/docserver/fulltext/linguistics/8/1/annurev-linguistics-031120-122924.pdf?expires=1729404555&id=id&accname=guest&checksum=BAC354EE7D776B2E3F70062009260611) 2022.01 [*Human Comparisons (Cognition & linguistics)*]
